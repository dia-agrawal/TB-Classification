# Example configuration for lightning_combined.py

# General experiment options
mode_type: "classifier"         # Options: base, classifier, tripletloss
batch_size: 64                  # Batch size for training (default: 64 for classifier/tripletloss, 512 for base)
num_workers: 4                  # Number of DataLoader workers
apply_specaugment: 0            # 1=True, 0=False; only used for classifier mode
checkpoint_path: null           # Path to checkpoint to resume from (optional)
class_weight: [8.0, 1.0]        # Class weights for classifier mode [bad_class_weight, good_class_weight]

# Model architecture parameters (passed to AudioMaskedAutoencoderViT)
model:
  num_mels: 256
  mel_len: 256
  patch_size: 16
  in_chans: 1
  embed_dim: 256
  encoder_depth: 6
  num_heads: 12
  decoder_embed_dim: 256
  decoder_depth: 6
  decoder_num_heads: 8
  mlp_ratio: 3
  norm_pix_loss: False

# You can add more options as needed for your experiment 